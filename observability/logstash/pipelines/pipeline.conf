###############
# LOGSTASH I/O
###############
input {
  beats { port => 5044 }                     # matches the filebeat.yml
  tcp   { port => 5001 codec => json_lines } # optional: send JSON over TCP
}

#####################
# FILTERS (ENRICH/MASK)
#####################
filter {
  # Parse nested JSON if message is a stringified JSON (fallback)
  json { source => "message" target => "json" skip_on_invalid_json => true }

  # Promote useful fields to root if present
  if [json][service] { mutate { add_field => { "service" => "%{[json][service]}" } } }
  if [json][env]     { mutate { add_field => { "env"     => "%{[json][env]}"     } } }
  if [json][reqId]   { mutate { add_field => { "reqId"   => "%{[json][reqId]}"   } } }
  if [json][level]   { mutate { add_field => { "level"   => "%{[json][level]}"   } } }
  if [json][latency_ms] { mutate { add_field => { "latency_ms" => "%{[json][latency_ms]}" } } }

  # GDPR-lite masking (demo). Adjust to the log schema.
  if [json][email] {
    mutate { gsub => ["[json][email]", "(?<=.{2}).(?=[^@]*?@)", "*"] }
  }
  if [json][phone] {
    mutate { gsub => ["[json][phone]", "(\\d{3})\\d+(\\d{2})", "\\1****\\2"] }
  }

  # Normalize timestamp if the JSON has it; otherwise rely on @timestamp
  date {
    match => ["[json][ts]", "ISO8601", "yyyy-MM-dd HH:mm:ss,SSS"]
    target => "@timestamp"
    timezone => "UTC"
  }
}

#############
# OUTPUT
#############

output {
  if "_grokparsefailure" in [tags] {
    elasticsearch { index => "deadletter-%{+YYYY.MM.dd}" }
  } else {
    elasticsearch {
      hosts => ["http://elasticsearch:9200"]
      index => "logs-%{[fields][service]}-%{+yyyy.MM.dd}"
    }
  }
}

# output {
#   elasticsearch {
#     hosts  => ["http://elasticsearch:9200"]
    # index by service if available, else default
 #    index  => "%{[service]:logs-generic}-%{+yyyy.MM.dd}"
#   }

  # Uncomment for debugging in console
  # stdout { codec => rubydebug }
# }
